# 📚 Scanner 전체 워크플로우

## 🔄 전체 프로세스 (매일 업데이트)

```
1. Scanner (오프라인) → Watchlist 생성
2. Features (오프라인) → 학습 데이터 생성
3. Train (오프라인) → ML 모델 학습
4. Server (실시간) → 진입 신호 감지
```

---

## 📋 단계별 상세 설명

### 1️⃣ Scanner - 종목 발굴 (매일 실행)

**목적:** 291개 전체 종목에서 조건 충족 종목 추출

```bash
cd scanner
python offline/scanner.py
```

**작동 방식:**
- FMP API로 전체 종목 프로필 + 히스토리 조회
- 필터링 조건:
  - ✅ 시가총액 >= $10M
  - ✅ 가격 $0.10 ~ $5.00
  - ✅ 평균 거래량 >= 100K
  - ✅ 15분봉 데이터 >= 100개
  - ✅ 패턴 점수 >= 40점

**출력:**
```
scanner/data/watchlist.json
```
- 약 200~300개 종목
- 점수 순으로 정렬

**예상 소요 시간:**
- 단일 프로세스: 약 2시간
- 병렬 처리 (6개): 약 20분

---

### 2️⃣ Features - 학습 데이터 생성 (매일 실행)

**목적:** Watchlist 종목의 15분봉 데이터로 피처 생성

```bash
python offline/features_offline.py
```

**작동 방식:**
- Watchlist 종목별 15분봉 히스토리 조회 (40일치)
- 이벤트 발굴:
  - RVOL >= 1.5
  - 베이스 범위 <= 8%
  - 직전 봉 변동 >= ±2%
- 라벨링:
  - 30분 후 +3% 이상 → 성공 (1)
  - 30분 후 -2% 이하 → 실패 (0)
  - 그 외 → 무효 (제외)

**출력:**
```
scanner/data/offline_features.parquet
```
- 약 수천~수만 개 이벤트
- 컬럼: `symbol`, `rvol_15m`, `base_range`, `spread_est`, `move_prev`, `label_30m`

**예상 소요 시간:** 약 10~20분

---

### 3️⃣ Train - ML 모델 학습 (매일 실행)

**목적:** LightGBM 모델 학습 및 심볼별 통계 생성

```bash
python offline/train_daily.py
```

**작동 방식:**
- `offline_features.parquet` 로드
- 80% 학습 / 20% 검증
- LightGBM 학습 (30분 후 성공 예측)
- 심볼별 임계값 계산:
  - 성공 사례의 60% 분위수 RVOL
  - 평균 스프레드
  - 최적 예측 임계값

**출력:**
```
scanner/data/model_lgbm_30m.bin      # 학습된 모델
scanner/data/symbol_stats.json       # 심볼별 통계
```

**평가 지표:**
- AUC (Area Under Curve)
- 0.70 이상: 좋음
- 0.60~0.70: 보통
- 0.60 미만: 부족 (더 많은 데이터 필요)

**예상 소요 시간:** 약 1~3분

---

### 4️⃣ Server - 실시간 감지 (계속 실행)

**목적:** 291개 종목 실시간 모니터링 → 진입 신호 발생

```bash
python server/server.py
```

**작동 방식:**

#### A. 효율적인 스캔 (10초마다)
1. **Batch Quote API** → 291개 현재가 일괄 조회 (6회 API 호출)
2. **변화 필터링** → 1% 이상 변화 or 0.5% 최근 변화
3. **상세 분석** → 선택된 종목만 15분봉 조회

#### B. ML 모델 예측
```python
입력: [rvol_15m, base_range, spread_est, move_prev]
출력: 성공 확률 (0.0 ~ 1.0)

if 확률 >= 심볼별_임계값:
    신호 발생!
```

#### C. 쿨다운 (중복 방지)
- 동일 종목: 30분 간 재신호 차단

**출력:**
- WebSocket으로 실시간 브로드캐스트
- 웹 UI (http://localhost:8800)

**API 사용량:**
```
291개 ÷ 50 = 6회 (배치 조회)
+ 변화 종목 상세 분석 (평균 10~30개)
= 약 50~100회 / 사이클
→ 분당 약 500~1000회 (한도: 3000)
```

---

## 🔁 매일 업데이트 필요 여부

### ✅ 매일 실행 필요:
1. **Scanner** - 종목 발굴
   - 시가총액, 거래량 등이 매일 변함
   - Watchlist 최신화
   
2. **Features** - 학습 데이터
   - 새로운 이벤트 수집
   - 데이터가 많을수록 모델 정확도 향상
   
3. **Train** - 모델 재학습
   - 최신 패턴 학습
   - 심볼별 통계 업데이트

### ⏰ 권장 스케줄:
```bash
# 미국 시장 종료 후 실행 (한국 시간 오전 6시)

# 1. Scanner (2시간 or 병렬 20분)
python offline/scanner.py

# 2. Features (10~20분)
python offline/features_offline.py

# 3. Train (1~3분)
python offline/train_daily.py

# 4. Server 재시작 (모델 리로드)
# Ctrl+C 후 다시 실행
python server/server.py
```

---

## 💡 핵심 개념

### "감지된 종목 1개"의 의미:
```
= 현재 실시간으로 진입 조건을 만족한 종목 수
```

**예시:** AIIO가 감지됨
- ✅ RVOL: 2.25x (거래량 급증)
- ✅ 베이스 범위: 2.19% (박스권 좁음)
- ✅ 봉 변동: +2.11% (상승 중)
- ✅ ML 확률: 75% (모델 예측)
- ✅ 임계값: 65% (심볼별 기준)
→ **진입 신호 발생!**

### 15분봉 기준 = 15분마다 분석?
**아닙니다!**

실제 작동:
```
10초마다:
├─ Batch Quote → 현재가 변화 감지 (즉시)
├─ 변화 있는 종목만 15분봉 조회
├─ 최신 봉 + 현재가로 피처 계산
└─ ML 모델 예측 → 신호 발생

= 실시간 감지 (10초 주기)
≠ 15분마다만 감지
```

**15분봉을 사용하는 이유:**
- 노이즈 감소 (1분봉보다 안정적)
- FMP API 데이터 충분 (44일치)
- 학습 데이터 품질 향상

---

## 🎯 15분봉 vs 멀티 타임프레임

### 현재 시스템 (15분봉 전용):
- ✅ 학습 데이터와 일관성
- ✅ ML 모델 적용 가능
- ✅ 안정적인 신호
- ❌ 15분 타이밍 놓칠 수 있음

### 대안 (멀티 타임프레임):
- 1분/5분/15분 각각 학습 필요
- 3개 모델 유지 필요
- 복잡도 증가

**결론:** 15분봉 + 현재가 조합이 최적

---

## 📊 성과 측정

### 모델 평가:
```bash
python offline/train_daily.py
```
출력 예시:
```
AUC: 0.72  ← 72% 정확도
피처 중요도:
  1. rvol_15m: 45%
  2. base_range: 30%
  3. spread_est: 15%
  4. move_prev: 10%
```

### 실전 성과:
- 매일 신호 개수 기록
- 진입 후 30분/1시간 수익률 추적
- Watchlist 점수와 실제 성과 비교

---

## ❓ FAQ

### Q1: 왜 학습을 매일 해야 하나요?
**A:** 시장은 매일 변합니다.
- 새로운 패턴 발생
- 심볼별 특성 변화
- 최신 데이터로 모델 개선

### Q2: Scanner는 얼마나 자주 실행하나요?
**A:** 하루 1회 (시장 종료 후)
- Watchlist 최신화
- 새로운 종목 발굴

### Q3: Server는 언제 재시작하나요?
**A:** 학습 완료 후 (모델 리로드)
- 새 모델 적용
- 통계 업데이트

### Q4: API 한도는 괜찮나요?
**A:** 고급 플랜 (분당 3000) → 충분
- Scanner: 하루 1회 (오프라인)
- Server: 분당 500~1000회
- 여유: 약 60~70%

---

## 🚀 시작하기

```bash
# 1. 초기 실행 (한 번만)
cd scanner
python offline/scanner.py          # 약 2시간
python offline/features_offline.py # 약 20분
python offline/train_daily.py      # 약 3분

# 2. 서버 시작
python server/server.py

# 3. 웹 UI 확인
# http://localhost:8800

# 4. 매일 아침 (미국 시장 종료 후)
# 1~3 단계 반복
```

---

## 📝 요약

```
Scanner → Features → Train → Server

오프라인 ─────────────────┐
                           ├→ Server (실시간 감지)
학습 데이터 + ML 모델 ────┘

15분봉 기준 + 현재가 실시간 감지 = 최적
```

**변경점 없이 이대로 진행하세요!** ✅

