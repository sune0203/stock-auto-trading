# offline/merge_batches.py
"""
ë°°ì¹˜ë³„ë¡œ ì‹¤í–‰ëœ ìŠ¤ìºë„ˆ ê²°ê³¼ë¥¼ ë³‘í•©
"""
import json
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
DATA_DIR = ROOT / "data"

def merge_batches():
    """
    watchlist_batch*.json íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ ë³‘í•©
    """
    batch_files = list(DATA_DIR.glob("watchlist_batch*.json"))
    
    if not batch_files:
        print("âŒ ë³‘í•©í•  ë°°ì¹˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“¦ {len(batch_files)}ê°œì˜ ë°°ì¹˜ íŒŒì¼ ë°œê²¬")
    print("=" * 70)
    
    all_results = []
    all_stats = {
        "total": 0,
        "no_profile": 0,
        "mcap_filtered": 0,
        "no_daily_data": 0,
        "price_filtered": 0,
        "no_1min_data": 0,
        "score_low": 0,
        "passed": 0
    }
    
    config = None
    
    # ê° ë°°ì¹˜ íŒŒì¼ ì½ê¸°
    for batch_file in sorted(batch_files):
        print(f"ğŸ“„ ì½ëŠ” ì¤‘: {batch_file.name}")
        
        with open(batch_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        # ê²°ê³¼ ë³‘í•©
        all_results.extend(data.get("detail", []))
        
        # í†µê³„ ë³‘í•©
        stats = data.get("stats", {})
        for key in all_stats:
            all_stats[key] += stats.get(key, 0)
        
        # ì„¤ì • ì €ì¥ (ì²« ë²ˆì§¸ ê²ƒ ì‚¬ìš©)
        if config is None:
            config = data.get("config", {})
        
        print(f"  âœ… {data.get('total', 0)}ê°œ ì¢…ëª©")
    
    # ì¤‘ë³µ ì œê±° (symbol ê¸°ì¤€, ì ìˆ˜ê°€ ë†’ì€ ê²ƒë§Œ)
    unique_results = {}
    for r in all_results:
        sym = r["symbol"]
        if sym not in unique_results or r["score"] > unique_results[sym]["score"]:
            unique_results[sym] = r
    
    final_results = list(unique_results.values())
    
    # ì ìˆ˜ ìˆœ ì •ë ¬
    final_results = sorted(final_results, key=lambda x: x["score"], reverse=True)
    
    # ë³‘í•©ëœ ê²°ê³¼ ì €ì¥
    out_path = DATA_DIR / "watchlist.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump({
            "symbols": [r["symbol"] for r in final_results],
            "detail": final_results,
            "total": len(final_results),
            "config": config,
            "stats": all_stats
        }, f, indent=2, ensure_ascii=False)
    
    print("\n" + "=" * 70)
    print("ğŸ¯ ë³‘í•© ì™„ë£Œ!")
    print("=" * 70)
    print(f"ì €ì¥ ê²½ë¡œ: {out_path}")
    print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼:")
    print(f"  ì´ ì²˜ë¦¬: {all_stats['total']} ì¢…ëª©")
    print(f"  ë°œê²¬: {len(final_results)} ì¢…ëª© (í†µê³¼ìœ¨: {len(final_results)/all_stats['total']*100:.3f}%)")
    
    if final_results:
        print(f"\nğŸ† ìƒìœ„ 10ê°œ ì¢…ëª©:")
        print("=" * 70)
        for i, r in enumerate(final_results[:10], 1):
            print(f"{i:2d}. {r['symbol']:6s} | ì ìˆ˜: {r['score']:3d} | ê°€ê²©: ${r['price']:7.2f} | "
                  f"ATR5: {r['atr5_pct']:5.2f}% | RVOL: {r['rvol_peak']:5.2f}")
    
    # ë°°ì¹˜ íŒŒì¼ ì •ë¦¬ ì—¬ë¶€ í™•ì¸
    print("\n" + "=" * 70)
    print("ğŸ’¡ ë°°ì¹˜ íŒŒì¼ ì •ë¦¬:")
    print(f"   {len(batch_files)}ê°œì˜ ë°°ì¹˜ íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤.")
    print(f"   ì‚­ì œí•˜ë ¤ë©´: python offline/cleanup_batches.py")

if __name__ == "__main__":
    merge_batches()

